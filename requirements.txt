llama-cpp-python
transformers>=4.43.2
torch==2.3.1 
accelerate 
vllm==0.5.3.post1 
wheel 
flash_attn==2.6.3 
trl 
peft 
bitsandbytes
