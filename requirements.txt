llama-cpp-python
transformers>=4.43.2
torch==2.3.1 
accelerate 
vllm>=0.5.5 
wheel 
flash_attn==2.6.3 
trl 
peft 
bitsandbytes
